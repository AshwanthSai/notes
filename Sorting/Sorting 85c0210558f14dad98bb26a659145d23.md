# Sorting

### Insertion Sort [Easy, Slow Sorting Algorithm]

---

- What is the idea behind Insertion Sort?
    
    **Take first element, A[1], compare with element on left. If smaller, swap and run compare, swap till 0th position in array.  Got from left to right. if item is smaller, compares from that position to the left.** 
    
    [https://www.youtube.com/watch?v=JU767SDMDvA](https://www.youtube.com/watch?v=JU767SDMDvA)
    
- What is the Big O notation for this? What are its features?
    
    for each I there are, I inned iterations. 
    
    So in total it is , 1 +  2 + 3 .. + N - 1.. = (N)(N - 1)/2 = O(N Square). - The absolute worse case.
    
- **What is a Inplace sort?**
    
    It is an inplace sort, it does not require an extra array of similiar size. 
    
- **What is stable sorting?**
    
    *A stable sorting algorithm* is the one that sorts the identical elements in their same order as they appear in the input, whilst unstable sorting *may not* satisfy the case.
    
    Stability may lead to faster algorithms. 
    
    Radix Sort - Repeated sorting on parts of the data. If first sort is not stable, it may lead to problems.
    

### Merge Sort [Divide and Conquer] - O(NLogN)

---

- What are its features ?
    
    Not an inplace sort. 
    
    But is a stable sort. - Only Swap when greater or less, does not swap when it is e
    **One of the fastest general purpose algorithms,** 
    
- What is the general idea?
    1. Break the array into smaller sub arrays 
    
    ![Untitled](Sorting%2085c0210558f14dad98bb26a659145d23/Untitled.png)
    
    1. Sort the indvidual arrays - Find the solution to sub problems
    2. Merge the indvidual arrays to one single array.
    
    ![Untitled](Sorting%2085c0210558f14dad98bb26a659145d23/Untitled%201.png)
    
- Why to divide the array into just approx two?
    
    What if the number of items is odd. 
    
    So (i + j/2), (i + j/2 + 1) to last
    
- What is the workhorse for Merge Sort?
    
    **The merge part is the workhorse.** 
    
    The two arrays are merged together. 
    Two pointers, one on the left and right. (i, j).
    
    if i < j then put into auxilary array.  if j < i control shifts to second array, compares and pushes to auxillary array. finish all iterations. 
    copy auxillary array to our array. We dont return auxillary array as this is a recursive function.
    
    ![Untitled](Sorting%2085c0210558f14dad98bb26a659145d23/Untitled%202.png)
    
- Workflow.
    - I**f there is some form of comparison, it means some work needs to be done.**
        
        ![Untitled](Sorting%2085c0210558f14dad98bb26a659145d23/Untitled%203.png)
        
    - **Divide the code into two recursive calls.**
        
        Left call moves up until there are only two elements in array. 
        Merges and control is shifted down.
        
        ![Untitled](Sorting%2085c0210558f14dad98bb26a659145d23/Untitled%204.png)
        
- What is the complexity?
    
    **Complexity of Merge Sort is nlogn.
    Merge and place to TA, copy from TA to original array. So complexity of Merge Function is O(2n).**
    

### Quick Sort -  One of the fastest sorting algorithms in practise.

---

- What are its features?
    
    It is an inplace sort.
    
    It is not a stable sort.
    
    Uses Divide and Conquer.
    
    Worst case O(N square), But these cases are rare.
    
- What is correct sorted order?
    
    The position of an item is same, in the sorted array.
    
    ![Untitled](Sorting%2085c0210558f14dad98bb26a659145d23/Untitled%205.png)
    
- What is the idea behind it ?
    
    If all of the items are in correct sorted order - then you dont need to sort. By definition it is a sorted array. 
    
    Repeatedly find item that is not in correct sorted order - do a little bit of work - place it into correct sorted order - then you kind of get a whole sorted order.
    
- What is the workhorse of quicksort?

---